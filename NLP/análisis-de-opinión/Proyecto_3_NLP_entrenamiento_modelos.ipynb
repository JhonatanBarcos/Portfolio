{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWd_SPzRQy5u"
      },
      "source": [
        "<img src='http://www.tsc.uc3m.es/~navia/figures/logo_uc3m_foot.jpg' width=800 />\n",
        "\n",
        "# Proyecto 3: Análisis de opinión\n",
        "\n",
        "### Procesado del Lenguaje Natural\n",
        "\n",
        "**Angel Navia Vázquez**\n",
        "\n",
        "  * 1.1 (January 2025) Revised and updated version\n",
        "\n",
        "Departamento de Teoría de la Señal y Comunicaciones\n",
        "\n",
        "**Universidad Carlos III de Madrid**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WACg3HfWQy5y"
      },
      "source": [
        "En este notebook debéis entrenar un clasificador de opinión utilizando los datos facilitados (**data_project_NLP_3_train.csv, data_project_NLP_3_val.csv**). En estos ficheros, las **opiniones positivas están codificadas como \"1\" y las negativas como \"0\"**.\n",
        "\n",
        "Tenéis total libertad para elegir la mejor implementación. El modelo final será evaluado en un conjunto de test (no proporcionado).\n",
        "\n",
        "Incluid aquí todas las pruebas de los diferentes modelos, así como la selección llevado a cabo. Se deberá guardar en ficheros el modelo elegido como ganador, para su uso posterior en el notebook \"Proyecto_3_NLP_mejor_modelo.ipynb\".\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar aquí las librerías necesarias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import joblib"
      ],
      "metadata": {
        "id": "EHjvzz9Fbvce"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vinculamos DRIVE para importar datos\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "MYDRIVE=\"/content/drive/MyDrive/2_CUATRI/NLP/LAB3/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dVhxUqNnfh3J",
        "outputId": "c5225719-172e-443d-f502-f4c53cfbce3f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar los datos de entrenamiento y validación proporcionados\n",
        "train_data = pd.read_csv(MYDRIVE+'data_project_NLP_3_train.csv')\n",
        "val_data = pd.read_csv(MYDRIVE+'data_project_NLP_3_val.csv')\n",
        "\n",
        "# Separamos en variables \"X\" e \"y\" cada dataset\n",
        "X_train = train_data['texto']\n",
        "y_train = train_data['opinion']\n",
        "\n",
        "X_val = val_data['texto']\n",
        "y_val = val_data['opinion']\n",
        "\n",
        "# Aplicamos vectorización Tf-Idf al conjunto de entrenamiento\n",
        "vectorizer = TfidfVectorizer(\n",
        "    min_df=5,\n",
        "    max_df=0.8,\n",
        "    max_features=10000,\n",
        "    ngram_range=(1, 2),\n",
        "    sublinear_tf=True,\n",
        ")\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = vectorizer.transform(X_val)"
      ],
      "metadata": {
        "id": "tyhCbqO5boXG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar los diferentes modelos\n",
        "# Logistic Regression\n",
        "clf_lr = LogisticRegression()\n",
        "clf_lr.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = clf_lr.predict(X_val_tfidf)\n",
        "\n",
        "# SVM\n",
        "clf_svm = SVC(probability=True)\n",
        "clf_svm.fit(X_train_tfidf, y_train)\n",
        "y_pred_svm = clf_svm.predict(X_val_tfidf)\n",
        "\n",
        "# Multinomial Naive Bayes\n",
        "clf_nb = MultinomialNB()\n",
        "clf_nb.fit(X_train_tfidf, y_train)\n",
        "y_pred_nb = clf_nb.predict(X_val_tfidf)\n",
        "\n",
        "# Random Forest\n",
        "clf_rf = RandomForestClassifier()\n",
        "clf_rf.fit(X_train_tfidf, y_train)\n",
        "y_pred_rf = clf_rf.predict(X_val_tfidf)"
      ],
      "metadata": {
        "id": "av9I7545cAzz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# elegir el modelo ganador\n",
        "# Hallamos la AUC de cada modelo y comparamos\n",
        "modelos = [clf_lr, clf_svm, clf_nb, clf_rf]\n",
        "nombres_modelos = ['Logistic Regression', 'SVM', 'Multinomial Naive Bayes', 'Random Forest']\n",
        "\n",
        "for nombre, modelo in zip(nombres_modelos, modelos):\n",
        "\n",
        "  if hasattr(modelo, 'predict_proba'):\n",
        "    y_pred = modelo.predict_proba(X_val_tfidf)[:,1]\n",
        "  else:\n",
        "    y_pred = modelo.predict(X_val_tfidf)\n",
        "\n",
        "  auc = roc_auc_score(y_val, y_pred)\n",
        "  print(f\"* {nombre}: AUC = {auc}\\n\")\n"
      ],
      "metadata": {
        "id": "W3A-8DKIcDaJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d9b4e47b-43c2-472b-e13c-ba59865df11a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Logistic Regression: AUC = 0.9022442872279435\n",
            "\n",
            "* SVM: AUC = 0.9122805964355143\n",
            "\n",
            "* Multinomial Naive Bayes: AUC = 0.8688216066299074\n",
            "\n",
            "* Random Forest: AUC = 0.8874139419753049\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Almacenar en ficheros el modelo ganador para su uso posterior\n",
        "\n",
        "# Guardamos el modelo SVM\n",
        "joblib.dump(clf_svm, MYDRIVE + 'modelo_ganador.pkl')\n",
        "\n",
        "# Guardamos el vectorizador usado\n",
        "joblib.dump(vectorizer, MYDRIVE + 'vectorizador_modelo_ganador.pkl')\n"
      ],
      "metadata": {
        "id": "d71vsdrwcF30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d5905fc5-485f-4fbd-86d5-568dcecaf579"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/2_CUATRI/NLP/LAB3/vectorizador_modelo_ganador.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}